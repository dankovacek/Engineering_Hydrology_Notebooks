{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Rainfall-Runoff Modelling\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we look at several ways of estimating a rainfall-runoff response hydrograph given that information availability is location-specific.\n",
    "\n",
    "First, we'll use the rational method to approximate peak flow based on empirical data.  We'll also use a slightly more complex model, the Soil Conservation Service Curve Number (SCS-CN) to do the same.  Both the rational method and SCS methods are examples of \"lumped\" models, where the basin is assumed to be homogeneous and characteristics are then \"lumped\" together.\n",
    "\n",
    "Finally, we'll use an open-source geospatial library to make a simple distributed model of the basin from digital elevation data (DEM).  We'll calculate the flow direction and flow accumulation in order to delineate a basin and define the stream network, and use this to construct an hydrograph from a precipitation event.\n",
    "\n",
    "In all cases, we'll relate the resulting flow to a practical problem involving water level in a hypothetical channel situated at the basin outlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  const JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# advanced statistics library\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mp\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# SEE COMMENTS ABOUT PYSHEDS LIBRARY IN NEXT CELL\n",
    "from pysheds.grid import Grid\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import LinearColorMapper, LogTicker, ColorBar, BasicTickFormatter, VBar, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Setup\n",
    "\n",
    "Let's imagine you had a summer job in Whistler working on a project to grade and re-pave the area around Day Lot 4, including installing drainage to capture water from the parking lot and divert it to a storm water collection system instead of draining into FitzSimmons Creek.  \n",
    "\n",
    "![Satellite Image of the Day Lot 4 area in Whistler](img/lot4_diagram1.png)\n",
    "\n",
    "It's summer and the project is scheduled to be completed by fall.  For the sake of this exercise, assume the slope of the parking lot area describes a catchment of roughly **1 $km^2$** and empties through a temporary channel into a catch basin to be treated before flowing into FitzSimmons Creek.  Unfortunately, beyond the outlet (red dot in the diagram above), the channel has to cross the pedestrian trail that follows the river left bank.  Assume the channel is rectangular in shape, and is 2m wide by 0.25m deep with a hydraulic grade slope of 0.5%.  \n",
    "\n",
    "* **Channel width (w)**: $2m$\n",
    "* **Channel Depth (h)**: $0.25m$\n",
    "* **Hydraulic Grade Line Slope (S)**: 0.005 (0.5%)\n",
    "* **Roughness (n)**: 0.017 (rough asphalt)\n",
    "\n",
    ">**Note:** Given the drainage area is only $1 km^2$, do you have a sense of what duration of rainfall is appropriate for estimating the peak of the runoff response hydrograph?  *i.e. 1h, 6h, 24h, 48h?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find & Import Precipitation Data\n",
    "\n",
    "We can use the application from the [Pacific Climate Impacts Consortium](https://data.pacificclimate.org/portal/pcds/map/) (PCIS) to retrieve climate observations in the Whistler area. For this exercise, we will use historical climate data from the Meteorological Service of Canada (MSC) station at Whistler, BC.  Using the *Observation Frequency* filter provided, there appear to be a few climate stations with hourly precipitation data:  \n",
    "\n",
    "![Location of Environment Canada climate stations at Whistler with hourly data.](img/pcds_hourly_stn.png)\n",
    "\n",
    "We'll look at one (*ID 1048899: Whistler (2014-2022)*) as an example.  Well, no we won't because it turns out this station does not actually have hourly data, nor do any of the others *except one* (925 - green triangle circled in red).  **You will always be responsible for your own data validation.**  In the PCIS database has hourly data available at only one location in the Whistler area, and it's from the Ministry of Forests, Lands, and Resource Operations Wildfire Management Branch (FLNRO-WMB) for a brief period in 2005 (ID 925 ZZ REMSATWX1).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import precipitation data\n",
    "# note that the ascii file uses the string 'None' for NaN \n",
    "# and we need to fix this.  \n",
    "hourly_df = pd.read_csv('../../notebook_data/notebook_4_data/925.ascii',\n",
    "header=1, na_values=[' None'], infer_datetime_format=True, parse_dates=[' time'])\n",
    "# note that the ascii format imports the column headers with spaces\n",
    "# that need to be cleaned up\n",
    "hourly_df.columns = [e.strip() for e in hourly_df.columns]\n",
    "hourly_df.set_index('time', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Data\n",
    "\n",
    "Here we will use the Bokeh data visualization library to plot the precipitation data.   The ability to zoom in and out of different time scales provides a different perspective and helps with data exploration and review.  We don't have much data in this case, but if we did, holy crow, look out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = ColumnDataSource(df)\n",
    "\n",
    "p = figure(title=f'Hourly Precipitation {df.index[0]:%Y-%m-%d} -{df.index[-1]:%Y-%m-%d}', width=750, height=300, x_axis_type='datetime')\n",
    "\n",
    "p.vbar(x='time', width=pd.Timedelta(hours=1), top='precipitation', \n",
    "bottom=0, source=datasource, legend_label='Precipitation', \n",
    "color='royalblue')\n",
    "\n",
    "p.legend.location = 'top_left'\n",
    "p.xaxis.axis_label = 'Date'\n",
    "p.yaxis.axis_label = 'Precipitation [mm]'\n",
    "p.toolbar_location='above'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Peak Runoff\n",
    "\n",
    "It is rare to find long-term records at a high frequency of measurement, so **we do the best we can with the information available**.  Below, we'll look at a few ways of constructing a hydrograph.  We want to construct a hydrograph because if we can accurately predict its peak (or more generally its shape), we can design hydraulic structures and other water management systems.  We'll start with a very basic estimate that has minimal information requirements, and move to more complex and information-intensive methods.  \n",
    "\n",
    "In the problem setup we asked *\"will the outlet channel be big enough\"*.  Water resources problems are often expressed in terms of risk, and typically for this kind of analysis we communicate risk in terms of annual exceedance probability (AEP).  In other words, what is the probability that the flow in the channel will exceed its capacity in a given year?  **These kinds of problems do not have a right answer, they are open-ended and subjective&mdash;meaning there is always some judgment that needs to be applied.**  The topic of risk will be discussed further in Notebook 5.  For now, we want to focus on a few ways of estimating (the peak of) a runoff hydrograph from precipitation data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rational Method\n",
    "\n",
    "Recall that the peak runoff for a small basin can be estimated by [the following](https://www.tad.usace.army.mil/Portals/53/docs/TAA/AEDDesignRequirements/AED%20Design%20Requirements-%20Hydrology%20Studies_Feb-11.pdf) from the US Army Corps of Engineers (USACE):\n",
    "\n",
    "$$Q = k\\cdot C\\cdot I \\cdot a$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* **k**: 0.278 [-]\n",
    "* **C**: runoff coefficient [-]\n",
    "* **I**: rainfall intensity [mm/hr]\n",
    "* **a**: drainage area [$km^2$]\n",
    "\n",
    "We have already estimated drainage area, and there are just two additional pieces of information we need to estimate the peak runoff for our basin.  The runoff coefficient \"C\" can be found in a table of empirical values in the USACE link above, and the rainfall intensity can be estimated from [Intensity-Duration-Frequency](https://climate.weather.gc.ca/prods_servs/engineering_e.html) curve data developed by Environment Canada.  [More information on IDF Curve usage](https://climatedata.ca/resource/best-practices-for-using-idf-curves/).  We can find IDF curves for specific locations using the [web application at climatedata.ca](https://climatedata.ca/download/#idf-download).  The IDF curve for Whistler is below:\n",
    "\n",
    "![IDF Curve for Whistler, BC.](img/IDF.png)\n",
    "\n",
    "We don't really know the appropriate duration yet for our basin, but we can select a few and run calculations to see how sensitive this model is to the duration.  The five diagonal lines represent different return periods (2, 5, 10, 20, 50, 100).  The return period is the inverse of the AEP, and again it represents the probability of occurrence **in any given year**, and it does not suggest an event of any magnitude will occur once in that return period.  \n",
    "\n",
    "Below we'll use a range of the values that we're not too sure about their effect on the estimated hydrograph (peak flow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rational_method_peak_flow(C, I, a):\n",
    "    \"\"\"Calculate peak flow (m^3/s) using the rational method.\n",
    "\n",
    "    Args:\n",
    "        C (float): runoff coefficient\n",
    "        I (float): rainfall intensity [mm/hr]\n",
    "        a (float): drainage area [km^2]\n",
    "    \"\"\"\n",
    "    return 0.278 * C * I * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we'll define an array of three runoff coefficient values \n",
    "# to get a sense of the range of possible conditions\n",
    "# minimum, maximum, and expected value\n",
    "C_values = [0.5, 0.9, 0.7]\n",
    "\n",
    "# for each return period, we'll read the minimum and maximum intensity\n",
    "# and use these to see the range of outcomes\n",
    "IDF_dict = {\n",
    "    5: (22, 45), # the 2 and 100 year intensities are 22mm, 45mm (5 min)\n",
    "    15: (14, 28),\n",
    "    60: (7, 15),\n",
    "    1440: (2, 4) # 1440 minutes is 24 hours\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the range of flow estimates for each C and each return period\n",
    "# and create a plot for each runoff coefficient\n",
    "figs = []\n",
    "rational_results = {}\n",
    "colors=['green', 'gold', 'orange', 'red']\n",
    "for k, (i_min, i_max) in IDF_dict.items(): \n",
    "    i = 0\n",
    "    p = figure(title=f'Duration={k}min', width=600, height=400) \n",
    "    for c in C_values:   \n",
    "        Q_min = rational_method_peak_flow(c, i_min, 1)\n",
    "        Q_max = rational_method_peak_flow(c, i_max, 1)\n",
    "        x = [2, 100]\n",
    "        y = [Q_min, Q_max]\n",
    "        p.line(x, y, legend_label=f'C={c}', color=colors[i])\n",
    "        p.yaxis.axis_label = 'Flow [m^3/s]'\n",
    "        p.xaxis.axis_label = 'Return Period'\n",
    "        p.legend.location = 'top_left'\n",
    "        i += 1\n",
    "\n",
    "    figs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import gridplot\n",
    "layout = gridplot(figs, ncols=2, width=350, height=300)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Pause and reflect**: From the plots above, is it more critical to get the correct duration, to select an appropriate return period, or to get an accurate estimate of the runoff coefficient?  In other words, how sensitive is the model to the parameters?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCS Unit Hydrograph Model\n",
    "\n",
    "Using the [Soil Conservation Service unit hydrograph model](https://www.hec.usace.army.mil/confluence/hmsdocs/hmstrm/surface-runoff/scs-unit-hydrograph-model), estimate the time of concentration, or the time it takes a drop of rain to flow from any point in the basin to the outlet assuming the area is a plane surface with homogeneous slope and roughness:  \n",
    "\n",
    "$$t = 6.94 \\frac{(L*n)^{0.6}}{I^{0.4}S^{0.3}}$$\n",
    "\n",
    "$$t_{sheet} = \\frac{0.007(NL)^{0.8}}{P_2^{0.5}S^{0.4}}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "\n",
    "Is this a reasonable assumption in general?  **Consider what effect this assumption has on the resulting peak flow.**  \n",
    "\n",
    "Lets reconstruct a runoff hydrograph at the outlet given the above information.  First, we import some precipitation data from Whistler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0.0011\n",
    "S = 0.005\n",
    "L = 100\n",
    "\n",
    "t_sheet = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainfall-Runoff Response by the Rational Method\n",
    "\n",
    "Below, we find a single precipitation event to use as an example for estimating a runoff hydrograph.  Below we plot a two week period where "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Volume to volmeteric flow units\n",
    "\n",
    "Runoff is typically measured in $\\frac{m^3}{s}$, so convert $\\frac{mm}{day}$ precipitation to $\\frac{m^3}{s}$ runoff.\n",
    "\n",
    "$$1 \\frac{mm}{day} \\times \\frac{1 m}{1000 mm} \\times \\frac{1 day}{24 h} \\times \\frac{1 h}{ 3600 s} \\times 1 km^2 \\times \\frac{1000 m \\times 1000 m}{1 km^2}= \\frac{1}{86.4} \\frac{m^3}{s}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to runoff volume\n",
    "drainage_area = 1 # km^2\n",
    "\n",
    "# runoff is typically measured in m^3/s (cms for short -- cubic metres per second), \n",
    "# so express the runoff in cms\n",
    "event_df['runoff_cms'] = event_df['Total Rain (mm)'] / 86.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the channel outlet has a rectangular shape of width 2m, how tall should our boots be?  Assume a 0.5% slope, and find a reasonable assumption for the roughness of asphalt.\n",
    "\n",
    "Recall the Manning equation:\n",
    "\n",
    "$$Q = \\frac{1}{n} A R^{2/3} S^{1/2}$$\n",
    "\n",
    "Where:\n",
    "* **n** is the manning roughness\n",
    "* **A** is cross sectional area of the flow\n",
    "* **R** hydraulic radius (area / wetted perimeter)\n",
    "* **S** is the channel slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify our given information\n",
    "w_channel = 2 # m\n",
    "S = 0.005 # channel slope\n",
    "n_factor = 0.017  # rough asphalt\n",
    "\n",
    "def calc_Q(d, w, S, n):\n",
    "    \"\"\"\n",
    "    Calculate flow from the Manning equation.\n",
    "    \"\"\"\n",
    "    A = d * w # flow area as (depth x width)\n",
    "    wp = w + 2 * d  # wetted perimeter\n",
    "    R = A / wp # hydraulic radius (area / wetted perimeter)\n",
    "    return (1/n) * A * R**(2/3) * S**(1/2)\n",
    "\n",
    "def solve_depth(w, n_factor, Q, S):\n",
    "    \"\"\"\n",
    "    Given a flow, a roughness factor, a channel slope, and a channel width, \n",
    "    calculate flow depth. \n",
    "    \"\"\"\n",
    "    e = 1 / 100  # solve within 1%\n",
    "    d = 0\n",
    "    Q_est = 0\n",
    "    n = 0\n",
    "    while (abs(Q_est - Q) > e) & (n < 1000):\n",
    "        Q_est = calc_Q(d, w, S, n_factor)\n",
    "#         print(Q, Q_est, abs(Q_est - Q))\n",
    "        d += 0.001\n",
    "        n += 1\n",
    "#     print('solved in {} iterations'.format(n))\n",
    "    return d \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each timestep, we want to solve for the depth of water at our outlet\n",
    "event_df['flow_depth_m'] = event_df['runoff_cms'].apply(lambda x: solve_depth(w_channel, n_factor, x, S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(event_df.index, event_df['flow_depth_m'])\n",
    "plt.ylabel('Flow depth [m]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Not only are our feet wet, but if we happen to be there the peak it's potentially dangerous.  As little as 10-15cm of water quickly enough can sweep you off your feet.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Recalculating Life](img/recalculating.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complex Implementation: Spatial Data\n",
    "\n",
    "As discussed in class, precipitation takes time to travel from where it fell to the basin outlet.  Next we will estimate the runoff response in a real catchment, just upstream from the parking lot example in the FitzSimmons Creek basin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Instantiate a grid from a DEM raster\n",
    "Some sample data is already included, but for extra data, see the [USGS hydrosheds project](https://www.hydrosheds.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = Grid.from_raster('data/n45w125_con_grid/n45w125_con/n45w125_con', data_name='dem')\n",
    "grid = Grid.from_ascii(path='../../data/notebook_5_data/n49w1235_con_grid.asc', \n",
    "                       data_name='dem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the nodata from -32768 so it doesn't throw off the \n",
    "# DEM plot\n",
    "grid.nodata = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the extents of the map\n",
    "map_extents = grid.extent\n",
    "min_x, max_x, min_y, max_y = map_extents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the DEM\n",
    "\n",
    "**NOTE:** The cell below may take up to 30 seconds to load.  Please be patient, it is thinking really hard. \n",
    "\n",
    "The code below will plot the Digital Elevation Model (DEM).  \n",
    "\n",
    "Do you recognize any features of the terrain?  Can you locate where it is?\n",
    "\n",
    "Hover over the map (or touch if using a touchscreen) to see the coordinates in decimal degree units.\n",
    "\n",
    "What does the [precision of the coordinates represent](http://wiki-1-1930356585.us-east-1.elb.amazonaws.com/wiki/index.php/Decimal_degrees)?  \n",
    "* i.e. what does 5 decimal places in decimal degrees equate to in kilometers?\n",
    "\n",
    "You can interact with the plot by using the tools on the left (in vertical order from top to bottom):\n",
    "* **pan:** move around the map\n",
    "* **box zoom:** draw a square to zoom in on\n",
    "* **wheel zoom:** use the mousewheel (or pinch gesture on a touchscreen) to zoom in\n",
    "* **box zoom:** draw a square to zoom in on\n",
    "* **tap**: not yet implemented (but you can see the coordinates)\n",
    "* **refresh**: reset the map\n",
    "* **hover**: see the coordinates when hovering over the map with a mouse or pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set bokeh plot tools\n",
    "tools = \"pan,wheel_zoom,box_zoom,reset,tap\"\n",
    "\n",
    "# show the precision of the decimal coordinates\n",
    "# in the plot to 5 decimal places\n",
    "TOOLTIPS = [\n",
    "    (\"(x,y)\", \"($x{1.11111}, $y{1.11111})\"),\n",
    "]\n",
    "\n",
    "# create a figure, setting the x and y ranges to the appropriate data bounds\n",
    "p1 = figure(title=\"DEM of the Lower Mainland of BC.  Hover to get coordintes.\", plot_width=600, plot_height=int(400),\n",
    "            x_range = map_extents[:2], y_range = map_extents[2:], \n",
    "            tools=tools, tooltips=TOOLTIPS)\n",
    "\n",
    "# map elevation to a colour spectrum\n",
    "color_mapper = LinearColorMapper(palette=\"Magma256\", low=-200, high=2400)\n",
    "\n",
    "# np.flipud flips the image data on a vertical axis\n",
    "adjusted_img = [np.flipud(grid.dem)]  \n",
    "\n",
    "p1.image(image=adjusted_img,   \n",
    "         x=[min_x],               # lower left x coord\n",
    "         y=[min_y],               # lower left y coord\n",
    "         dw=[max_x-min_x],        # *data space* width of image\n",
    "         dh=[max_y-min_y],        # *data space* height of image\n",
    "         color_mapper=color_mapper\n",
    ")\n",
    "\n",
    "color_bar = ColorBar(color_mapper=color_mapper, #ticker=Ticker(),\n",
    "                     label_standoff=12, border_line_color=None, location=(0,0))\n",
    "\n",
    "p1.add_layout(color_bar, 'right')\n",
    "\n",
    "\n",
    "show(p1)\n",
    "\n",
    "# -123.15512, 49.41293\n",
    "#-123.14657, 49.41080\n",
    "-123.14350, 49.40251"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve flats in DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.resolve_flats('dem', out_name='inflated_dem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify flow direction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         N    NE    E    SE    S    SW    W    NW\n",
    "dirmap = (64,  128,  1,   2,    4,   8,    16,  32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.flowdir(data='inflated_dem', out_name='dir', dirmap=dirmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "plt.imshow(grid.dir, extent=grid.extent, cmap='viridis', zorder=2)\n",
    "boundaries = ([0] + sorted(list(dirmap)))\n",
    "plt.colorbar(boundaries= boundaries,\n",
    "             values=sorted(dirmap))\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Flow direction grid')\n",
    "plt.grid(zorder=-1)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('data/img/flow_direction.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the values of the raster as an array\n",
    "grid.dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of the raster\n",
    "grid.dir.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delineate a Catchment\n",
    "\n",
    "Note that once you've executed the code in the cells below,\n",
    "if you change the Point of Concentration (POC), you'll\n",
    "need to go back to Step 1 and execute the code from there again.\n",
    "\n",
    "This needs to be done to re-initialize the extents of the data \n",
    "that are loaded into memory.  The intermediary steps trim the extent\n",
    "of the DEM and you will get an error message saying:\n",
    "\n",
    "\n",
    ">`ValueError: Pour point (-123.94307, 49.40783) is out of bounds for dataset with bbox (-123.195000000122, 49.39999999984, -123.15333333347199, 49.421666666498).`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Point of Concentration (POC) / Catchment Outlet (a.k.a. pour point) \n",
    "# This location is a tributary of the Capilano River, just above the reservoir above\n",
    "# Cleveland Dam.\n",
    "x, y = -123.14657, 49.41080\n",
    "x, y = -123.14350, 49.40251\n",
    "\n",
    "# And just for good measure, here's the little tributary in the south-west corner.\n",
    "# Note the instructions above about reloading the original data to re-initialize\n",
    "# the DEM\n",
    "x, y = -123.15512, 49.41293\n",
    "\n",
    "# Delineate the catchment\n",
    "grid.clip_to('dem')\n",
    "grid.catchment(data='dir', x=x, y=y, dirmap=dirmap, out_name='catch',\n",
    "               recursionlimit=15000, xytype='label', nodata_out=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the bounding box to the catchment we've chosen\n",
    "grid.clip_to('catch', pad=(1,1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view of the catchment\n",
    "catch = grid.view('catch', nodata=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape to see if we've estimated close enough to the \n",
    "# actual river to delineate the catchment successfully\n",
    "print(catch.shape)\n",
    "# if we get dimensions of < 10, we've missed and instead pointed at some \n",
    "# little hillslope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.extent)\n",
    "ext_1 = grid.extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the catchment\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "plt.grid('on', zorder=0)\n",
    "im = ax.imshow(catch, extent=grid.extent, zorder=1, cmap='viridis')\n",
    "plt.colorbar(im, ax=ax, boundaries=boundaries, values=sorted(dirmap), label='Flow Direction')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Delineated Catchment')\n",
    "# plt.savefig('data/img/catchment.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get flow accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.accumulation(data='catch', dirmap=dirmap, out_name='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.patch.set_alpha(0)\n",
    "plt.grid('on', zorder=0)\n",
    "acc_img = np.where(grid.mask, grid.acc + 1, np.nan)\n",
    "im = ax.imshow(acc_img, extent=grid.extent, zorder=2,\n",
    "               cmap='cubehelix',\n",
    "               norm=colors.LogNorm(1, grid.acc.max()))\n",
    "plt.colorbar(im, ax=ax, label='Upstream Cells')\n",
    "plt.title('Flow Accumulation')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "# plt.savefig('data/img/flow_accumulation.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distances to upstream cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.flow_distance(data='catch', x=x, y=y, dirmap=dirmap, out_name='dist',\n",
    "                   xytype='label', nodata_out=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.patch.set_alpha(0)\n",
    "plt.grid('on', zorder=0)\n",
    "im = ax.imshow(grid.dist, extent=grid.extent, zorder=2,\n",
    "               cmap='cubehelix_r')\n",
    "plt.colorbar(im, ax=ax, label='Distance to outlet (cells)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Flow Distance')\n",
    "# plt.savefig('data/img/flow_distance.png', bbox_inches='tight'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_threshold=20\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.patch.set_alpha(0)\n",
    "plt.grid('on', zorder=0)\n",
    "streamnetwork_img = np.where(acc_img>area_threshold, 100, 1+acc_img*0)\n",
    "# print([['nan' if np.isnan(i) else cmap[i] for i in j] for j in streamnetwork_img])\n",
    "labels = {1:'Catchment', 2: 'Outside Catchment', 100: 'Stream Network'}\n",
    "cmap = {1: [0.247, 0.552, 0.266, 0.5], \n",
    "        100: [0.074, 0.231, 0.764, 0.8],\n",
    "       2: [0.760, 0.760, 0.760, 0.8]}\n",
    "\n",
    "arrayShow = np.array([[cmap[2] if np.isnan(i) else cmap[i] for i in j] for j in streamnetwork_img])    \n",
    "## create patches as legend\n",
    "\n",
    "patches =[mp.Patch(color=cmap[i],label=labels[i]) for i in cmap]\n",
    "\n",
    "# streamnetwork_img = np.where(grid.mask, > 100, 10 , 1)\n",
    "# im = ax.imshow(streamnetwork_img, extent=grid.extent, zorder=2,\n",
    "#                 cmap='cubehelix')\n",
    "im = ax.imshow(arrayShow)\n",
    "plt.legend(handles=patches, loc=1, borderaxespad=0.)\n",
    "# plt.colorbar(im, ax=ax, label='Upstream Cells')\n",
    "plt.title('Stream network')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "# plt.savefig('data/img/stream_network.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate weighted travel distance\n",
    "\n",
    "Assign a travel time to each cell based on the assumption that water travels at one speed (slower) until it reaches a stream network, at which point its speed increases dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "plt.grid('on', zorder=0)\n",
    "grid.clip_to('catch', pad=(1,1,1,1))\n",
    "acc = grid.view('acc')\n",
    "\n",
    "# calculate weights.\n",
    "# assume the threshold is 100 accumulation cells \n",
    "# (of roughly 500mx500m) results in stream\n",
    "weights = (np.where(acc, 0.1, 0)\n",
    "               + np.where((0 < acc) & (acc <= 100), 1, 0)).ravel()\n",
    "\n",
    "weighted_dist = grid.flow_distance(data='catch', x=x, y=y, weights=weights,\n",
    "                   xytype='label', inplace=False)\n",
    "\n",
    "im = ax.imshow(weighted_dist, extent=grid.extent, zorder=2,\n",
    "               cmap='cubehelix_r')\n",
    "# plt.legend(handles=patches, loc=1, borderaxespad=0.)\n",
    "plt.colorbar(im, ax=ax, label='Upstream Cells')\n",
    "plt.title('Stream network')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Rainfall-Runoff Model\n",
    "\n",
    "Now that we have weighted flow distances for each cell in the delineated catchment, we can apply precipitation to each 'cell' in order to reconstruct a flow hydrograph.  \n",
    "\n",
    "First, we must figure out the cell dimensions.  From the [USGS Hydrosheds information](https://hydrosheds.cr.usgs.gov/datadownload.php), we know the resolution is 15 (degree) seconds.  Because the earth is not a perfect sphere, [coordinate projection systems](https://epsg.io/) (CRS) are used to approximate the surface of the earth so that spatial distances can be more accurately represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells can be grouped by their weighted distance to the outlet to simplify \n",
    "# the process of calculating the contribution of each cell to flow at the outlet\n",
    "\n",
    "dist_df = pd.DataFrame()\n",
    "dist_df['weighted_dist'] = weighted_dist.flatten()\n",
    "# trim the distance dataframe to include only the cells in the catchment,\n",
    "# and round the travel time to the nearest one (hour)\n",
    "dist_df = dist_df[dist_df['weighted_dist'] > 0].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = sample_df.index.values[0]\n",
    "end_date = sample_df.index.values[-1]\n",
    "# create an hourly dataframe based on the sample precipitation event\n",
    "# then resample the values to evenly distribute the total daily \n",
    "# precipitation to hourly precipitation\n",
    "resampled_df = sample_df.resample('1H').pad() / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our 'weighted distance' has just provided a relative difference between the flow accumulation cells and non-flow-accumulation cells.  We still must convert these values to some time-dependent form.\n",
    "\n",
    "For this exercise, we will assume the average velocity of water is 1 m/s value for the flow accumulation cells, and 0.1 m/s for the other cells.  Therefore precipitation will take on average 300s (0.0833 h) and 3000s (0.833 h) to travel to the outlet for flow-accumulation and non-flow-accumulation cells, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of cells of each distance\n",
    "grouped_dists = pd.DataFrame(dist_df.groupby('weighted_dist').size())\n",
    "grouped_dists.columns = ['num_cells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unit hydrographs for each timestep\n",
    "runoff_df = pd.DataFrame(np.zeros(len(resampled_df)))\n",
    "runoff_df.columns = ['Total Precip (mm)']\n",
    "runoff_df.index = resampled_df.index.copy()\n",
    "end_date = pd.to_datetime(runoff_df.index.values[-1]) + pd.DateOffset(hours=1)\n",
    "max_distance = max(grouped_dists.index)\n",
    "\n",
    "extended_df = pd.DataFrame()\n",
    "extended_df['Total Precip (mm)'] = [0 for e in range(int(max_distance) + 1)]\n",
    "extended_df.index = pd.date_range(end_date, periods=max_distance + 1, freq='1H')\n",
    "\n",
    "# append the extra time to the runoff dataframe\n",
    "runoff_df = runoff_df.append(extended_df)\n",
    "runoff_df['Runoff (cms)'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: if you re-run the cell below, you need to run the cell above as well, or the runoff dataframe will not reset and the values will keep increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = 300 # assume each pixel represents 300m x 300m \n",
    "runoff_coefficient = 0.3\n",
    "\n",
    "\n",
    "for ind, row in resampled_df.iterrows():\n",
    "    this_hyd = resampled_df[['Total Precip (mm)']].copy()\n",
    "    for weight_dist, num_cells in grouped_dists.iterrows():\n",
    "        try: \n",
    "            outlet_time = ind + pd.DateOffset(hours=weight_dist)\n",
    "            precip = num_cells.values[0] * row['Total Precip (mm)']\n",
    "            runoff_vol = precip * runoff_coefficient / 1000 * cell_size**2 \n",
    "            runoff_rate = runoff_vol  / 3600  # convert to m^3/s from m^3/h\n",
    "            runoff_df.loc[outlet_time, 'Runoff (cms)'] += runoff_rate\n",
    "        except KeyError as err:\n",
    "            print('error')\n",
    "            break\n",
    "#             print(err)\n",
    "#             print(ind, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,4))\n",
    "\n",
    "sample_start = pd.to_datetime('2014-12-01')\n",
    "sample_end = pd.to_datetime('2014-12-15')\n",
    "\n",
    "sample_df = df[(df.index > sample_start) & (df.index < sample_end)][['Total Precip (mm)', 'Total Snow (cm)', 'Total Rain (mm)']]\n",
    "\n",
    "# print(sample_df.head())\n",
    "# plot the original daily precip\n",
    "# ax.plot(sample_df.index, sample_df['Total Precip (mm)'], label=\"Total Precip [mm]\")\n",
    "# ax.plot(sample_df.index, sample_df['Total Snow (cm)'], label=\"Total Snow [cm]\")\n",
    "# ax.plot(sample_df.index, sample_df['Total Rain (mm)'], label=\"Total Rain [mm]\")\n",
    "ax.plot(runoff_df.index, runoff_df['Runoff (cms)'], label=\"Runoff\")\n",
    "\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Runoff [cms]', color='blue')\n",
    "ax.set_title('Example Rainfall-Runoff Model')\n",
    "ax.legend(loc='upper left')\n",
    "ax.tick_params(axis='y', colors='blue')\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(sample_df.index, sample_df['Total Rain (mm)'], \n",
    "         color='green',\n",
    "         label=\"Total Rain\")\n",
    "ax1.set_ylabel('Precipitation [mm]', color='green')\n",
    "ax1.tick_params(axis='y', colors='green')\n",
    "ax1.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the Peak Unit Runoff\n",
    "\n",
    "First, estimate the drainage area.  Then, find the peak hourly flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA = round(grouped_dists.sum().values[0] * 0.3 * 0.3, 0)\n",
    "max_UR = runoff_df['Runoff (cms)'].max() / DA * 1000\n",
    "print('The drainage area is {} km^2 and the peak Unit Runoff is {} L/s/km^2'.format(DA, int(max_UR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the limitations of the approach.  Where do uncertainties exist?\n",
    "\n",
    "* assumed precipitation is constant across days\n",
    "* assumed constant runoff coefficient\n",
    "* assumed two weights for travel time, constant across time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question for Reflection\n",
    "\n",
    "For the first part where we estimated the water level at the parking lot outlet based on an assumption that there was zero infiltration, assuming all else is equal, how could we reduce the maximum water level to 5 cm?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
